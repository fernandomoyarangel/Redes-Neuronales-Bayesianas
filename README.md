# TFG - M茅todos de Inferencia en Redes Neuronales Bayesianas

Este repositorio contiene diferentes notebooks que exploran t茅cnicas modernas de deep learning con enfoque en modelos probabil铆sticos, estimaci贸n de incertidumbre y explicabilidad, aplicados a tareas de regresi贸n, clasificaci贸n y segmentaci贸n de im谩genes.

##  Contenidos

### `Datos-Segmentacion.ipynb`
Preprocesamiento y preparaci贸n de datos de **CityScapes** para el proyecto de segmentaci贸n de im谩genes. Aqu铆 se organizan y procesan los datos de entrada que se utilizan en modelos posteriores.

### `Segmentacion-Imagenes.ipynb`
Comparativa entre modelos deterministas y bayesianos (MC Dropout) sobre la misma arquitectura de SegNet en tareas de **segmentaci贸n de im谩genes**. Adem谩s, se incorpora:
-  Evaluaci贸n de la incertidumbre en las predicciones
-  Skip connections
-  T茅cnicas de explicabilidad como **Grad-CAM**

### `Sistema-Frenado.ipynb`
Aplicaci贸n pr谩ctica del modelo con MC Dropout en un sistema de frenado. Se analiza la calidad de las segmentaciones de los modelos anteriores en un escenario de decisi贸n real, donde la estimaci贸n de incertidumbre es cr铆tica.

### `IncertidumbreRegresion.ipynb`
Ejemplo did谩ctico de regresi贸n donde se compara:
- Red neuronal determinista
- Red neuronal bayesiana con inferencia variacional (VI) usando **TensorFlow Probability (TFP)**
- Red neuronal bayesiana con MCMC, en concreto **NUTS** usando **TensorFlow Probability (TFP)**

Se muestra c贸mo var铆a la incertidumbre seg煤n el enfoque adoptado.

### `bbb-clasificacion-f.ipynb`
Implementaci贸n de una red neuronal convolucional bayesiana usando **Bayes By Backprop (BBB)** con el local reparametrization trick. Se aplica al dataset **CIFAR-10** para tareas de clasificaci贸n, comparando rendimiento y comportamiento frente a redes deterministas.

---

##  Tecnolog铆as utilizadas
- TensorFlow & TensorFlow Probability
- PyTorch
- Grad-CAM
- MC Dropout
- Inferencia Variacional (VI)
- NUTS (No-U-Turn Sampler)
- CIFAR-10

---

##  Objetivo
Explorar y aplicar t茅cnicas de deep learning bayesiano para evaluar modelos m谩s robustos, confiables y transparentes. El enfoque se centra en:
- Entender las principales ventajas y desventajas de las redes neuronales bayesianas
- Medir la incertidumbre asociada a las predicciones
- Aplicar estas ideas a problemas reales de clasificaci贸n, regresi贸n y segmentaci贸n
- Sacar conclusiones de los m茅todos de inferencia bayesiana m谩s 贸ptimos en la pr谩ctica

---

##  Autor
**Fernando Francisco Moya Rangel**  
Trabajo de Fin de Grado (TFG)

---

##  Referencias

- Shridhar, K., Laumann, F., & Liwicki, M. (2019). *A comprehensive guide to Bayesian convolutional neural network with variational inference*. arXiv preprint [arXiv:1901.02731](https://arxiv.org/abs/1901.02731)

- Shridhar, K., Laumann, F., & Liwicki, M. (2018). *Uncertainty estimations by softplus normalization in Bayesian convolutional neural networks with variational inference*. arXiv preprint [arXiv:1806.05978](https://arxiv.org/abs/1806.05978)

