# TFG - M√©todos de Inferencia en Redes Neuronales Bayesianas

Este repositorio contiene diferentes notebooks que exploran t√©cnicas modernas de deep learning con enfoque en modelos probabil√≠sticos, estimaci√≥n de incertidumbre y explicabilidad, aplicados a tareas de regresi√≥n, clasificaci√≥n y segmentaci√≥n de im√°genes.

## üìÅ Contenidos

### `Datos-Segmentacion.ipynb`
Preprocesamiento y preparaci√≥n de datos de **CityScapes** para el proyecto de segmentaci√≥n de im√°genes. Aqu√≠ se organizan y procesan los datos de entrada que se utilizan en modelos posteriores.

### `Segmentacion-Imagenes.ipynb`
Comparativa entre modelos deterministas y bayesianos (MC Dropout) sobre la misma arquitectura de SegNet en tareas de **segmentaci√≥n de im√°genes**. Adem√°s, se incorpora:
- üéØ Evaluaci√≥n de la incertidumbre en las predicciones
- üîÅ Skip connections
- üîç T√©cnicas de explicabilidad como **Grad-CAM**

### `Sistema-Frenado.ipynb`
Aplicaci√≥n pr√°ctica del modelo con MC Dropout en un sistema de frenado. Se analiza la calidad de las segmentaciones de los modelos anteriores en un escenario de decisi√≥n real, donde la estimaci√≥n de incertidumbre es cr√≠tica.

### `IncertidumbreRegresion.ipynb`
Ejemplo did√°ctico de regresi√≥n donde se compara:
- Red neuronal determinista
- Red neuronal bayesiana con inferencia variacional (VI) usando **TensorFlow Probability (TFP)**
- Red neuronal bayesiana con MCMC, en concreto **NUTS** usando **TensorFlow Probability (TFP)**

Se muestra c√≥mo var√≠a la incertidumbre seg√∫n el enfoque adoptado.

### `bbb-clasificacion-f.ipynb`
Implementaci√≥n de una red neuronal convolucional bayesiana usando **Bayes By Backprop (BBB)** con el local reparametrization trick. Se aplica al dataset **CIFAR-10** para tareas de clasificaci√≥n, comparando rendimiento y comportamiento frente a redes deterministas.

---

## üß† Tecnolog√≠as utilizadas
- TensorFlow & TensorFlow Probability
- PyTorch
- Grad-CAM
- MC Dropout
- Inferencia Variacional (VI)
- NUTS (No-U-Turn Sampler)
- CIFAR-10

---

## üìå Objetivo
Explorar y aplicar t√©cnicas de deep learning bayesiano para evaluar modelos m√°s robustos, confiables y transparentes. El enfoque se centra en:
- Entender las principales ventajas y desventajas de las redes neuronales bayesianas
- Medir la incertidumbre asociada a las predicciones
- Aplicar estas ideas a problemas reales de clasificaci√≥n, regresi√≥n y segmentaci√≥n
- Sacar conclusiones de los m√©todos de inferencia bayesiana m√°s √≥ptimos en la pr√°ctica

---
## üõ†Ô∏è Recursos utilizados
El desarrollo del Trabajo de Fin de Grado se ha llevado a cabo principalmente utilizando los siguientes entornos y plataformas:

- **Google Colab Pro**: entorno principal para el entrenamiento y evaluaci√≥n de los modelos en la segmentaci√≥n de im√°genes. Se ha aprovechado el acceso a GPU (Tesla A100) para acelerar el entrenamiento de las redes convolucionales con tantas capas y par√°metros a optimizar.
- **Kaggle**: empleado en los experimentos de regresi√≥n y clasificaci√≥n. Gracias al acceso gratuito a GPU y al entorno reproducible de notebooks, fue posible acelerar el proceso de entrenamiento y almacenar los resultados de forma eficiente.

Estas herramientas han permitido un flujo de trabajo flexible y eficiente en la experimentaci√≥n con modelos bayesianos de deep learning.

---


## üë§ Autor
**Fernando Francisco Moya Rangel**  
Trabajo de Fin de Grado (TFG)

---

## üìö Referencias

- Shridhar, K., Laumann, F., & Liwicki, M. (2019). *A comprehensive guide to Bayesian convolutional neural network with variational inference*. arXiv preprint [arXiv:1901.02731](https://arxiv.org/abs/1901.02731)

- Shridhar, K., Laumann, F., & Liwicki, M. (2018). *Uncertainty estimations by softplus normalization in Bayesian convolutional neural networks with variational inference*. arXiv preprint [arXiv:1806.05978](https://arxiv.org/abs/1806.05978)
  
- Kendall, A., Badrinarayanan, V., & Cipolla, R. (2016). *Bayesian SegNet: Model Uncertainty in Deep Convolutional Encoder-Decoder Architectures for Scene Understanding*. arXiv preprint [arXiv:1511.02680](https://arxiv.org/abs/1511.02680)
  
- Duerr, O., Loui, A., & Luckow, C. (2021). *Probabilistic Deep Learning with Python, Keras and TensorFlow Probability*. Addison-Wesley Professional.

